{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0656adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c5bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"expense_dataset.csv\", parse_dates=[\"year_month\"])\n",
    "\n",
    "# Ensure sorted\n",
    "df = df.sort_values([\"company_id\", \"category\", \"year_month\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e541122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Engineering\n",
    "# ----------------------------\n",
    "df[\"month\"] = df[\"year_month\"].dt.month\n",
    "df[\"trend_index\"] = (df[\"year_month\"].dt.year - df[\"year_month\"].dt.year.min())*12 + df[\"month\"]\n",
    "\n",
    "# Cyclical encoding for seasonality\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "\n",
    "# Missingness indicators\n",
    "df[\"is_yoy_missing\"] = df[\"yoy_pct_change\"].isnull().astype(int)\n",
    "df[\"is_pct_prev_missing\"] = df[\"pct_change_prev\"].isnull().astype(int)\n",
    "\n",
    "# Fill NA values safely\n",
    "for col in [\"yoy_pct_change\", \"pct_change_prev\", \"roll_mean_3\", \"roll_std_3\"]:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# Ratios\n",
    "eps = 1e-6\n",
    "df[\"lag_ratio_1_2\"] = df[\"lag_1\"] / (df[\"lag_2\"] + eps)\n",
    "df[\"lag_ratio_1_rollmean\"] = df[\"lag_1\"] / (df[\"roll_mean_3\"] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9143a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Define Features & Target\n",
    "# ----------------------------\n",
    "target = \"monthly_total\"\n",
    "features = [\n",
    "    \"lag_1\",\"lag_2\",\"lag_3\",\n",
    "    \"roll_mean_3\",\"roll_std_3\",\n",
    "    \"yoy_same_month\",\"yoy_pct_change\",\"pct_change_prev\",\n",
    "    \"n_transactions\",\n",
    "    \"is_sparse_category\",\"fallback_used\",\"seasonal_peak_flag\",\"external_signal_index\",\"confidence_flag\",\n",
    "    \"trend_index\",\"month_sin\",\"month_cos\",\n",
    "    \"lag_ratio_1_2\",\"lag_ratio_1_rollmean\"\n",
    "]\n",
    "\n",
    "# Drop any rows without target\n",
    "df = df[df[target].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17ea56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's l1: 4184.11\tvalid_1's l1: 5222.4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's l1: 5741.68\tvalid_1's l1: 11676.9\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's l1: 6522.54\tvalid_1's l1: 7662.14\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's l1: 6031.29\tvalid_1's l1: 6823.68\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's l1: 5853.81\tvalid_1's l1: 13952.6\n",
      "\n",
      "Cross-validation results:\n",
      "    val_month  Baseline_MAE     Ridge_MAE  LightGBM_MAE\n",
      "0  2024-08-01  51027.189464  27204.273806   5222.397977\n",
      "1  2024-09-01  73360.148600  45492.573298  11676.852124\n",
      "2  2024-10-01  78914.143934  31229.751354   7662.142477\n",
      "3  2024-11-01  61249.490227  37137.422301   6823.677568\n",
      "4  2024-12-01  76895.929167  45781.804780  13952.579467\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4. Rolling Cross-Validation\n",
    "# ----------------------------\n",
    "def rolling_cv(df, features, target, n_folds=3):\n",
    "    metrics = []\n",
    "    unique_months = sorted(df[\"year_month\"].unique())\n",
    "    horizon = 1  # one-step ahead\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        train_end = - (n_folds - i)\n",
    "        train_months = unique_months[:train_end]\n",
    "        val_month = unique_months[train_end]\n",
    "        \n",
    "        train = df[df[\"year_month\"].isin(train_months)]\n",
    "        val = df[df[\"year_month\"]==val_month]\n",
    "        \n",
    "        X_train, y_train = train[features], train[target]\n",
    "        X_val, y_val = val[features], val[target]\n",
    "        \n",
    "        # --- Baseline ---\n",
    "        baseline = val[\"lag_1\"].values\n",
    "        mae_base = mean_absolute_error(y_val, baseline)\n",
    "        \n",
    "        # --- Ridge Regression ---\n",
    "        ridge = Ridge(alpha=0.1)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        preds_ridge = ridge.predict(X_val)\n",
    "        mae_ridge = mean_absolute_error(y_val, preds_ridge)\n",
    "        \n",
    "        # --- LightGBM ---\n",
    "        lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "        lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
    "        \n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"mae\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 63,\n",
    "            \"max_depth\": 10,\n",
    "            \"lambda_l2\": 0.01,\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"bagging_fraction\": 0.9,\n",
    "            \"verbose\": -1\n",
    "        }\n",
    "        \n",
    "        model = lgb.train(\n",
    "                    params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_val],\n",
    "                    num_boost_round=1000,\n",
    "                    callbacks=[early_stopping(50), log_evaluation(0)]  # 50 rounds patience\n",
    "                )\n",
    "            \n",
    "        preds_lgb = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        mae_lgb = mean_absolute_error(y_val, preds_lgb)\n",
    "        \n",
    "        metrics.append({\n",
    "            \"val_month\": str(val_month)[:10],\n",
    "            \"Baseline_MAE\": mae_base,\n",
    "            \"Ridge_MAE\": mae_ridge,\n",
    "            \"LightGBM_MAE\": mae_lgb\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "cv_results = rolling_cv(df, features, target, n_folds=5)\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db493aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.9, feature_fraction=0.9, lambda_l2=0.01,\n",
       "              learning_rate=0.05, max_depth=10, n_estimators=1000,\n",
       "              num_leaves=63, objective=&#x27;regression&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.9, feature_fraction=0.9, lambda_l2=0.01,\n",
       "              learning_rate=0.05, max_depth=10, n_estimators=1000,\n",
       "              num_leaves=63, objective=&#x27;regression&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.9, feature_fraction=0.9, lambda_l2=0.01,\n",
       "              learning_rate=0.05, max_depth=10, n_estimators=1000,\n",
       "              num_leaves=63, objective='regression')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5. Train Final Model\n",
    "# ----------------------------\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "final_model = lgb.LGBMRegressor(\n",
    "    objective=\"regression\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,\n",
    "    lambda_l2=0.01,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.9\n",
    ")\n",
    "final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7acee27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next month forecast:\n",
      "     company_id    category year_month  predicted_amount\n",
      "23            1  Consulting 2025-01-01     380058.714121\n",
      "108           1   Marketing 2025-01-01     209406.236779\n",
      "160           1    Training 2025-01-01      59204.253749\n",
      "177           1      Travel 2025-01-01     314283.668252\n",
      "198           1   Utilities 2025-01-01      62514.245362\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 6. Predict Next Month\n",
    "# ----------------------------\n",
    "# Get last available month\n",
    "last_month = df[\"year_month\"].max()\n",
    "next_month = last_month + pd.DateOffset(months=1)\n",
    "\n",
    "# Prepare prediction rows (for each category in last month)\n",
    "latest = df[df[\"year_month\"]==last_month].copy()\n",
    "latest[\"year_month\"] = next_month\n",
    "\n",
    "X_pred = latest[features]\n",
    "preds = final_model.predict(X_pred)\n",
    "\n",
    "latest[\"predicted_amount\"] = preds\n",
    "print(\"\\nNext month forecast:\")\n",
    "print(latest[[\"company_id\",\"category\",\"year_month\",\"predicted_amount\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d586e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Predictions saved to predicted_expenses.csv\n"
     ]
    }
   ],
   "source": [
    "# 7. Save Predictions\n",
    "# ----------------------------\n",
    "latest[[\"company_id\",\"category\",\"year_month\",\"predicted_amount\"]].to_csv(\"predicted_expenses.csv\", index=False)\n",
    "print(\"\\n✅ Predictions saved to predicted_expenses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c255893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as final_expense_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(final_model, \"final_expense_model.pkl\")\n",
    "print(\"✅ Model saved as final_expense_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52bf4bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([380058.71412094, 209406.23677897,  59204.25374859, 314283.66825185,\n",
       "        62514.24536178, 380875.54617521,  63074.43530787, 197636.37107558,\n",
       "        14978.47649895, 191931.6573579 ,  37502.61022165, 241978.33767833,\n",
       "       215935.88327295,  18537.90783226,  19518.70621035, 172085.83088725,\n",
       "        40127.38370229, 251471.35422599, 215988.9396215 , 198326.26838963,\n",
       "        63907.58536626,  62272.12523805,  52383.51263316,  99587.97743439,\n",
       "       270729.92972827, 103875.3288225 ,  30702.80106508, 208749.68822307,\n",
       "       414097.35044812,  50535.11753435, 447999.04120621, 538948.93772987,\n",
       "        60174.05257727, 140168.36670106,  59972.60868185, 263273.6743737 ,\n",
       "        42672.17572753, 486542.62117178, 238552.24569771,  99065.47044976,\n",
       "        18848.0095712 , 111305.39880173, 326095.6501288 , 129290.80936291,\n",
       "       149931.45495336,  24840.68142621,  57184.36530573,  45435.22692182])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"final_expense_model.pkl\")\n",
    "\n",
    "# Make predictions as usual\n",
    "preds = loaded_model.predict(X_pred)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2537b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
